#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åæ€æ¨¡å¼é—®ç­”æ™ºèƒ½ä½“
åŸºäºLangGraphæ¡†æ¶å®ç°çš„ç®€å•åæ€æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿç”Ÿæˆåˆå§‹å“åº”ã€è‡ªæˆ‘è¯„ä¼°å¹¶ä¼˜åŒ–å›ç­”ã€‚
"""

import os
import sys
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(root_dir)

from typing import TypedDict, Annotated, Literal
import operator
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from models import init_model


class ReflectionQAState(TypedDict):
    """åæ€æ™ºèƒ½ä½“çš„çŠ¶æ€å®šä¹‰
    
    å±æ€§:
        messages: å¯¹è¯å†å²æ¶ˆæ¯åˆ—è¡¨
        reflection: å¯¹å“åº”çš„åæ€å†…å®¹
        is_refined: å“åº”æ˜¯å¦å·²ä¼˜åŒ–
        iterations: åæ€è¿­ä»£æ¬¡æ•°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆé»˜è®¤å€¼ï¼‰
    """
    messages: Annotated[list, operator.add]  # å¯¹è¯å†å²ï¼Œæ”¯æŒç´¯åŠ 
    reflection: str  # åæ€å†…å®¹
    is_refined: bool  # æ˜¯å¦å·²ä¼˜åŒ–
    iterations: int  # å·²è¿­ä»£æ¬¡æ•°
    max_iterations: int  # æœ€å¤§è¿­ä»£æ¬¡æ•°


# åˆå§‹åŒ–å…¨å±€æ¨¡å‹å®ä¾‹
model = init_model()


def generate_response(state: ReflectionQAState) -> dict:
    """ç”Ÿæˆåˆå§‹å“åº”èŠ‚ç‚¹
    
    å‚æ•°:
        state: å½“å‰çŠ¶æ€
    
    è¿”å›:
        æ›´æ–°åçš„çŠ¶æ€
    """
    print("ğŸ”„ æ­£åœ¨ç”Ÿæˆåˆå§‹å“åº”...")
    
    # ç¡®ä¿max_iterationsæœ‰é»˜è®¤å€¼
    max_iterations = state.get("max_iterations", 2)
    
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt = SystemMessage(content="""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½çš„é—®ç­”åŠ©æ‰‹ã€‚
    è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œä¿æŒå›ç­”æ¸…æ™°ã€å‡†ç¡®ã€å…¨é¢ã€‚
    """)
    
    # è°ƒç”¨æ¨¡å‹ç”Ÿæˆå“åº”
    response = model.invoke([system_prompt] + state["messages"])
    
    return {
        "messages": [response],
        "iterations": state.get("iterations", 0) + 1,
        "is_refined": False,
        "max_iterations": max_iterations
    }


def reflect_on_answer(state: ReflectionQAState) -> dict:
    """åæ€è¯„ä¼°èŠ‚ç‚¹
    
    å‚æ•°:
        state: å½“å‰çŠ¶æ€
    
    è¿”å›:
        æ›´æ–°åçš„çŠ¶æ€ï¼ˆåŒ…å«åæ€å†…å®¹ï¼‰
    """
    print("ğŸ” æ­£åœ¨åæ€è¯„ä¼°å“åº”...")
    
    messages = state["messages"]
    if not messages:
        return {"reflection": "æ²¡æœ‰å¯åæ€çš„æ¶ˆæ¯ã€‚"}
    
    # æå–ç”¨æˆ·é—®é¢˜å’ŒåŠ©æ‰‹å“åº”
    user_question = None
    assistant_response = None
    
    for msg in messages:
        if isinstance(msg, HumanMessage):
            user_question = msg.content
        elif isinstance(msg, AIMessage):
            assistant_response = msg.content
    
    if not user_question or not assistant_response:
        return {"reflection": "æ— æ³•æå–ç”¨æˆ·é—®é¢˜æˆ–åŠ©æ‰‹å“åº”ã€‚"}
    
    # ç”Ÿæˆåæ€
    reflection_system_prompt = SystemMessage(content="""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯„ä¼°è€…ï¼Œè´Ÿè´£å¯¹é—®ç­”è´¨é‡è¿›è¡Œä¸¥æ ¼è¯„ä¼°ã€‚
    è¯·å®¢è§‚åˆ†æå“åº”çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼Œå¹¶æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚
    """)
    
    reflection_query = f"""
    è¯·è¯„ä¼°ä»¥ä¸‹å¯¹ç”¨æˆ·é—®é¢˜çš„å›ç­”ï¼š
    
    ç”¨æˆ·é—®é¢˜ï¼š{user_question}
    åŠ©æ‰‹å›ç­”ï¼š{assistant_response}
    
    è¯„ä¼°åº”åŒ…æ‹¬ï¼š
    1. å›ç­”çš„ä¼˜ç‚¹ï¼ˆå‡†ç¡®æ€§ã€ç›¸å…³æ€§ã€æ¸…æ™°åº¦ç­‰ï¼‰
    2. å›ç­”çš„ä¸è¶³ï¼ˆä¿¡æ¯ç¼ºå¤±ã€é”™è¯¯ã€è¡¨è¿°ä¸æ¸…ç­‰ï¼‰
    3. å…·ä½“çš„æ”¹è¿›å»ºè®®
    """.strip()
    
    reflection_result = model.invoke([
        reflection_system_prompt,
        HumanMessage(content=reflection_query)
    ])
    
    return {"reflection": reflection_result.content}


def revise_answer(state: ReflectionQAState) -> dict:
    """ä¿®è®¢ä¼˜åŒ–èŠ‚ç‚¹
    
    å‚æ•°:
        state: å½“å‰çŠ¶æ€
    
    è¿”å›:
        æ›´æ–°åçš„çŠ¶æ€ï¼ˆåŒ…å«ä¼˜åŒ–åçš„å“åº”ï¼‰
    """
    print("ğŸ“ æ­£åœ¨æ ¹æ®åæ€ä¼˜åŒ–å“åº”...")
    
    messages = state["messages"]
    reflection = state["reflection"]
    
    if not messages or not reflection:
        return {"is_refined": True}
    
    # æå–ç”¨æˆ·é—®é¢˜å’Œåˆå§‹å“åº”
    user_question = None
    initial_response = None
    
    for msg in messages:
        if isinstance(msg, HumanMessage):
            user_question = msg.content
        elif isinstance(msg, AIMessage):
            initial_response = msg.content
    
    if not user_question or not initial_response:
        return {"is_refined": True}
    
    # ç”Ÿæˆä¼˜åŒ–åçš„å“åº”
    revision_system_prompt = SystemMessage(content="""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹ä¼˜åŒ–è€…ï¼Œè´Ÿè´£æ ¹æ®åæ€æ„è§æ”¹è¿›å›ç­”ã€‚
    è¯·ä¿æŒåŸæ„çš„åŒæ—¶ï¼Œè§£å†³æ‰€æœ‰æŒ‡å‡ºçš„é—®é¢˜ï¼Œä½¿å›ç­”æ›´åŠ å®Œç¾ã€‚
    """)
    
    revision_query = f"""
    è¯·æ ¹æ®ä»¥ä¸‹åæ€æ„è§ï¼Œä¼˜åŒ–åŠ©æ‰‹çš„å›ç­”ï¼š
    
    ç”¨æˆ·é—®é¢˜ï¼š{user_question}
    åˆå§‹å›ç­”ï¼š{initial_response}
    åæ€æ„è§ï¼š{reflection}
    
    ä¼˜åŒ–åçš„å›ç­”åº”ï¼š
    1. ä¿ç•™åŸæœ‰å›ç­”çš„ä¼˜ç‚¹
    2. è§£å†³åæ€ä¸­æŒ‡å‡ºçš„æ‰€æœ‰é—®é¢˜
    3. ä¿æŒå›ç­”çš„æ¸…æ™°ã€å‡†ç¡®å’Œå…¨é¢
    4. ä¸è¦æ·»åŠ ä¸é—®é¢˜æ— å…³çš„å†…å®¹
    """.strip()
    
    revised_response = model.invoke([
        revision_system_prompt,
        HumanMessage(content=revision_query)
    ])
    
    # æ›¿æ¢æœ€åä¸€æ¡æ¶ˆæ¯ä¸ºä¼˜åŒ–åçš„å“åº”
    updated_messages = messages[:-1] + [revised_response]
    
    return {
        "messages": updated_messages,
        "is_refined": True,
        "iterations": state.get("iterations", 0) + 1
    }


def should_reflect(state: ReflectionQAState) -> Literal["reflect", END]:
    """æ¡ä»¶è¾¹ï¼šæ˜¯å¦éœ€è¦åæ€
    
    å‚æ•°:
        state: å½“å‰çŠ¶æ€
    
    è¿”å›:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    max_iterations = state.get("max_iterations", 2)
    current_iterations = state.get("iterations", 0)
    
    if not state.get("is_refined", False) and current_iterations < max_iterations:
        return "reflect"
    return END


def should_revise(state: ReflectionQAState) -> Literal["revise", END]:
    """æ¡ä»¶è¾¹ï¼šæ˜¯å¦éœ€è¦ä¿®è®¢
    
    å‚æ•°:
        state: å½“å‰çŠ¶æ€
    
    è¿”å›:
        ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    return "revise"


def build_reflection_qa_graph() -> StateGraph:
    """æ„å»ºåæ€é—®ç­”å›¾
    
    è¿”å›:
        ç¼–è¯‘åçš„çŠ¶æ€å›¾
    """
    print("ğŸ“Š æ­£åœ¨æ„å»ºåæ€é—®ç­”å›¾...")
    
    # åˆ›å»ºçŠ¶æ€å›¾å®ä¾‹
    graph_builder = StateGraph(ReflectionQAState)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("generate", generate_response)
    graph_builder.add_node("reflect", reflect_on_answer)
    graph_builder.add_node("revise", revise_answer)
    
    # æ·»åŠ è¾¹
    graph_builder.add_edge(START, "generate")
    
    # ç”Ÿæˆå“åº”åï¼Œæ ¹æ®æ¡ä»¶å†³å®šæ˜¯å¦åæ€
    graph_builder.add_conditional_edges(
        "generate",
        should_reflect,
        {"reflect": "reflect", END: END}
    )
    
    # åæ€åï¼Œå†³å®šæ˜¯å¦ä¿®è®¢
    graph_builder.add_conditional_edges(
        "reflect",
        should_revise,
        {"revise": "revise", END: END}
    )
    
    # ä¿®è®¢åç»“æŸ
    graph_builder.add_edge("revise", END)
    
    # ç¼–è¯‘å›¾
    return graph_builder.compile()

QAAgent=build_reflection_qa_graph()

def run_reflection_qa_agent(question: str, max_iterations: int = 2) -> dict:
    """è¿è¡Œåæ€é—®ç­”æ™ºèƒ½ä½“
    
    å‚æ•°:
        question: ç”¨æˆ·é—®é¢˜
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
    
    è¿”å›:
        æ™ºèƒ½ä½“è¿è¡Œç»“æœ
    """
    print(f"\nğŸ“‹ ç”¨æˆ·é—®é¢˜: {question}")
    print("=" * 60)
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "reflection": "",
        "is_refined": False,
        "iterations": 0,
        "max_iterations": max_iterations
    }
    
    # æ„å»ºå¹¶è¿è¡Œå›¾
    reflection_graph = build_reflection_qa_graph()
    
    try:
        # ç”Ÿæˆæµç¨‹å›¾ï¼ˆå¯é€‰ï¼‰
        if not os.path.exists("images"):
            os.makedirs("images")
        
        try:
            reflection_graph.get_graph(xray=True).draw_mermaid_png(
                output_file_path="images/reflection_qa_graph.png"
            )
            print("ğŸ“ˆ æµç¨‹å›¾å·²ä¿å­˜åˆ°: images/reflection_qa_graph.png")
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆæµç¨‹å›¾å¤±è´¥: {e}")
        
        # è¿è¡Œæ™ºèƒ½ä½“
        config = {"run_name": "reflection_qa_agent"}
        result = reflection_graph.invoke(initial_state,config)
        return result
        
    except Exception as e:
        print(f"âŒ æ™ºèƒ½ä½“è¿è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•åæ€é—®ç­”æ™ºèƒ½ä½“"""
    
    # ç¤ºä¾‹é—®é¢˜
    test_questions = [
        "ä»€ä¹ˆæ˜¯LangGraphï¼Œå®ƒä¸ä¼ ç»Ÿçš„LangChainæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
        "è§£é‡Šä¸€ä¸‹Pythonä¸­çš„è£…é¥°å™¨ï¼Œå¹¶ç»™å‡ºå‡ ä¸ªå®ç”¨çš„ä¾‹å­ã€‚",
        "å¦‚ä½•ä¼˜åŒ–RAGç³»ç»Ÿçš„æ£€ç´¢æ•ˆæœï¼Ÿ"
    ]
    
    print("ğŸš€ åæ€æ¨¡å¼é—®ç­”æ™ºèƒ½ä½“å¯åŠ¨")
    print("=" * 60)
    
    try:
        # é€‰æ‹©ä¸€ä¸ªæµ‹è¯•é—®é¢˜
        question = test_questions[0]
        
        # è¿è¡Œæ™ºèƒ½ä½“
        result = run_reflection_qa_agent(question, max_iterations=2)
        
        print("=" * 60)
        print("âœ… æ™ºèƒ½ä½“è¿è¡Œå®Œæˆ")
        print("=" * 60)
        
        # è¾“å‡ºç»“æœ
        print("ğŸ“Œ æœ€ç»ˆå›ç­”:")
        print(result['messages'][-1].content)
        print("\nğŸ’­ åæ€å†…å®¹:")
        print(result['reflection'])
        print(f"\nğŸ”¢ è¿­ä»£æ¬¡æ•°: {result['iterations']}")
        print(f"ğŸ¯ æ˜¯å¦ä¼˜åŒ–: {'æ˜¯' if result['is_refined'] else 'å¦'}")
        
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºå‡ºé”™: {e}")
    finally:
        print("\n" + "=" * 60)
        print("ğŸ“‹ åæ€æ¨¡å¼é—®ç­”æ™ºèƒ½ä½“ç»“æŸ")
